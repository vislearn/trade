{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from trade.datasets import GMM,DataSet2DGMM\n",
    "from trade.models import set_up_sequence_INN_DoubleWell\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from trade.plots import eval_pdf_on_grid_2D\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helper functions:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_INN(base_path:str,use_last:bool = False,device:str = \"cuda:0\"):\n",
    "\n",
    "    config_i = yaml.safe_load(Path(base_path + \"/hparams.yaml\").read_text())\n",
    "    state_dict_folder_i = base_path + f\"/checkpoints/\"\n",
    "\n",
    "    files = os.listdir(state_dict_folder_i)\n",
    "\n",
    "    \n",
    "    for f in files:\n",
    "        print(f)\n",
    "        #Use the last recorded state dict\n",
    "        if use_last:\n",
    "\n",
    "            if f == \"last.ckpt\":\n",
    "                state_dict_path_i = os.path.join(state_dict_folder_i,f)\n",
    "                break\n",
    "\n",
    "        #Use the best performing state dict\n",
    "        else:\n",
    "            if f.startswith(\"checkpoint_epoch\"):\n",
    "                state_dict_path_i = os.path.join(state_dict_folder_i,f)\n",
    "                break\n",
    "\n",
    "    config_i[\"device\"] = device\n",
    "\n",
    "    INN_i = set_up_sequence_INN_DoubleWell(config=config_i)\n",
    "    INN_i.load_state_dict(state_dict_path_i)\n",
    "    INN_i.train(False)\n",
    "\n",
    "    print(state_dict_path_i)\n",
    "\n",
    "    return INN_i,config_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_beta(x,beta,gmm,Z = None):\n",
    "    q_beta = gmm(x).pow(beta)\n",
    "\n",
    "    if Z is None:\n",
    "        return q_beta\n",
    "    \n",
    "    else:\n",
    "        return q_beta / Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_loader_dict_2D_GMM(T_list_eval,n_samples):\n",
    "    validation_data_loader_dict = {}\n",
    "\n",
    "    for i,T_i in enumerate(T_list_eval):\n",
    "\n",
    "        T_i = round(T_i,5)\n",
    "        print(f\"Loading validation data for T = {T_i}\")\n",
    "\n",
    "        DS_i = DataSet2DGMM(\n",
    "            d = 2,\n",
    "            mode = \"validation\",\n",
    "            temperature_list=[T_i],\n",
    "            base_path=\"../data/2D_GMM/\",\n",
    "            n_samples=n_samples\n",
    "            )\n",
    "\n",
    "        DL_i = DataLoader(\n",
    "            DS_i,\n",
    "            batch_size = 1000,\n",
    "            shuffle = False,\n",
    "            num_workers = 4\n",
    "        )\n",
    "\n",
    "        validation_data_loader_dict[f\"{T_i}\"] = DL_i\n",
    "\n",
    "    return validation_data_loader_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the validation data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_list = torch.linspace(np.log(0.1),np.log(10),20).exp()\n",
    "T_list = torch.cat((T_list,torch.tensor([1.0])))\n",
    "T_list = [round(T_list.sort().values[i].item(),5) for i in range(len(T_list))]\n",
    "\n",
    "a = 7\n",
    "T_list_eval = T_list[10 - a:-(10 - a)]\n",
    "\n",
    "validation_data_loader_dict = get_validation_loader_dict_2D_GMM(T_list_eval = T_list_eval,n_samples = 80000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the paths to the trained models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.path.expanduser(\"~\")\n",
    "\n",
    "base_path_TRADE_grid =          \"../results/runs_2D_GMM/Path to your trained model/lightning_logs/version_0\"\n",
    "base_path_TRADE_no_grid =       \"../results/runs_2D_GMM/Path to your trained model/lightning_logs/version_0\"\n",
    "base_path_reverse_KL =          \"../results/runs_2D_GMM/Path to your trained model/lightning_logs/version_0\"\n",
    "base_path_reverse_KL_nll =      \"../results/runs_2D_GMM/Path to your trained model/lightning_logs/version_0\"\n",
    "base_path_nll_only =            \"../results/runs_2D_GMM/Path to your trained model/lightning_logs/version_0\"\n",
    "base_path_reweighting =         \"../results/runs_2D_GMM/Path to your trained model/lightning_logs/version_0\"\n",
    "base_path_volume_preserving =   \"../results/runs_2D_GMM/Path to your trained model/lightning_logs/version_0\"\n",
    "\n",
    "base_paths_dict = {\n",
    "    \"TRADE_grid\":base_path_TRADE_grid,\n",
    "    \"TRADE_no_grid\":base_path_TRADE_no_grid,\n",
    "    \"nll_only\":base_path_nll_only,\n",
    "    \"reverse_KL\":base_path_reverse_KL,\n",
    "    \"reverse_KL_nll\":base_path_reverse_KL_nll,\n",
    "    \"reweighting\":base_path_reweighting,\n",
    "    \"volume preserving\":base_path_volume_preserving\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INN_dict = {}\n",
    "config_dict = {}\n",
    "for key in base_paths_dict:\n",
    "    INN_k,config_k = load_INN(base_path = base_paths_dict[key],device=device,use_last=False)\n",
    "    INN_dict[key] = INN_k\n",
    "    config_dict[key] = config_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the validation nll\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = torch.tensor([\n",
    "            [-1.0,2.0],\n",
    "            [3.0,7.0],\n",
    "            [-4.0,2.0],\n",
    "            [-2.0,-4.0],\n",
    "            [0.0,4.0],\n",
    "            [5.0,-2.0]\n",
    "        ])\n",
    "\n",
    "#Covariance matrices\n",
    "S = torch.tensor([\n",
    "        [[ 0.2778,  0.4797],\n",
    "        [ 0.4797,  0.8615]],\n",
    "\n",
    "        [[ 0.8958, -0.0249],\n",
    "        [-0.0249,  0.1001]],\n",
    "\n",
    "        [[ 1.3074,  0.9223],\n",
    "        [ 0.9223,  0.7744]],\n",
    "\n",
    "        [[ 0.0305,  0.0142],\n",
    "        [ 0.0142,  0.4409]],\n",
    "\n",
    "        [[ 0.0463,  0.0294],\n",
    "        [ 0.0294,  0.3441]],\n",
    "        \n",
    "        [[ 0.15,  0.0294],\n",
    "        [ 0.0294,  1.5]]])\n",
    "\n",
    "gmm = GMM(means = means,covs=S,device=device)\n",
    "\n",
    "# Load the approximated partition functions for the power-scaled target distribution\n",
    "with open(\"../data/2D_GMM/Z_T.json\",\"r\") as f:\n",
    "    Z_T_dict = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_KLD_dicts = {}\n",
    "error_val_KLD_dicts = {}\n",
    "\n",
    "n_bootstrap = 20\n",
    "\n",
    "for T_i in T_list_eval:\n",
    "    val_KLD_dicts[f\"{T_i}\"] = {}\n",
    "    error_val_KLD_dicts[f\"{T_i}\"] = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for k in INN_dict:\n",
    "        print(\"evaluate \",k)\n",
    "\n",
    "        for T_i in T_list_eval:\n",
    "            T_i = round(T_i,5)\n",
    "            \n",
    "            DL_i = validation_data_loader_dict[f\"{T_i}\"]\n",
    "\n",
    "            log_p_theta_val = torch.zeros([0])\n",
    "            log_p_gt_val = torch.zeros([0])\n",
    "\n",
    "            for j,(beta_batch,x_batch) in enumerate(DL_i):\n",
    "                \n",
    "                #Model log likelihood\n",
    "                log_p_theta_val_i = INN_dict[k].log_prob(x_batch.to(device),beta_tensor=beta_batch.to(device))\n",
    "                log_p_theta_val = torch.cat((log_p_theta_val,log_p_theta_val_i.detach().cpu()),0)\n",
    "\n",
    "                #Ground truth log likelihood\n",
    "                log_p_gt_val_i = p_beta(x_batch.to(device),beta = 1 / T_i,gmm = gmm,Z = Z_T_dict[f\"{T_i}\"]).log()\n",
    "                log_p_gt_val = torch.cat((log_p_gt_val,log_p_gt_val_i.detach().cpu()),0)\n",
    "\n",
    "            assert(log_p_gt_val.shape == log_p_theta_val.shape)\n",
    "            \n",
    "            #Apply bootstrapping to estimate the deviation of the evaluation nlls\n",
    "            samples = np.zeros(n_bootstrap)\n",
    "\n",
    "            for i in range(n_bootstrap):\n",
    "                indices = np.random.randint(0,len(log_p_theta_val),len(log_p_theta_val))\n",
    "            \n",
    "                samples[i] = (log_p_gt_val[indices] - log_p_theta_val[indices]).mean()\n",
    "\n",
    "            mean_samples = samples.mean()\n",
    "            error_i = np.sqrt(np.square(samples - mean_samples).sum() / (n_bootstrap - 1))\n",
    "            error_val_KLD_dicts[f\"{T_i}\"][k] = error_i    \n",
    "\n",
    "            #Get the log likelihood of the validation set\n",
    "            val_KLD_i = (log_p_gt_val - log_p_theta_val).mean().item()\n",
    "            val_KLD_dicts[f\"{T_i}\"][k] = val_KLD_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(val_KLD_dicts)\n",
    "\n",
    "# Function to highlight the minimum value in each column\n",
    "def highlight_min(s):\n",
    "    is_min = s == s.min()\n",
    "    return ['font-weight: bold;' if v else '' for v in is_min]\n",
    "\n",
    "# Apply the style\n",
    "df.style.apply(highlight_min, subset=pd.IndexSlice[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_print_list = [[0.20691,0.33598,0.54556],[0.88587,1.0,1.12884],[1.83298,2.97635,4.83293]]\n",
    "\n",
    "row_name_dict = {\n",
    "    \"nll_only\":\"NLL + lat. TS\",\n",
    "    \"TRADE_grid\":\"TRADE (grid)\",\n",
    "    \"TRADE_no_grid\":\"TRADE (no grid)\",\n",
    "    \"reverse_KL\":\"Reverse KLD\",\n",
    "    \"reverse_KL_nll\":\"NLL + Reverse KLD\",\n",
    "    \"reweighting\":\"Reweighting\",\n",
    "    \"volume preserving\":\"Volume Preserving\",\n",
    "    \"gt\":\"Ground Truth\"\n",
    "}\n",
    "\n",
    "highlight_color = \"lightgray\"\n",
    "rows_to_highlight = [\"TRADE_grid\",\"TRADE_no_grid\"]\n",
    "\n",
    "#Get the best value in each colume:\n",
    "is_best_dict = {}\n",
    "for c,T_print in enumerate(T_print_list):\n",
    "    for T_i in T_print:\n",
    "\n",
    "        is_best_dict[f\"{T_i}\"] = {}\n",
    "\n",
    "        min_key = None\n",
    "\n",
    "        for k in INN_dict:\n",
    "            is_best_dict[f\"{T_i}\"][k] = False\n",
    "\n",
    "            if (min_key is None) or (val_KLD_dicts[f'{T_i}'][k] < val_KLD_dicts[f'{T_i}'][min_key]):\n",
    "                min_key = k\n",
    "\n",
    "        is_best_dict[f\"{T_i}\"][min_key] = True\n",
    "\n",
    "    table_str = \"\\\\begin{tabularx}{\\\\textwidth}{|c|\"\n",
    "\n",
    "    for i in range(len(T_print)):\n",
    "        table_str = table_str + \">{\\centering\\\\arraybackslash}X|\"\n",
    "    table_str = table_str+ \"}\\n\\hline\\n\"\n",
    "\n",
    "    #Column names\n",
    "    for T_i in T_print:\n",
    "        table_str += f\"&KLD $T = {T_i}\\downarrow$\"\n",
    "    table_str += \"\\\\\\\\\\n\\hline\\n\"\n",
    "\n",
    "    for k in base_paths_dict.keys():\n",
    "\n",
    "        if k in rows_to_highlight:\n",
    "            table_str += \"\\\\rowcolor{\" + highlight_color + \"}\"\n",
    "\n",
    "        table_str += f\"{row_name_dict[k]}\"\n",
    "\n",
    "        for T_i in T_print:\n",
    "\n",
    "            magnitude = np.floor(np.log10(abs( error_val_KLD_dicts[f\"{T_i}\"][k]))) \n",
    "            magnitude = abs(int(magnitude - 2))\n",
    "\n",
    "            if is_best_dict[f'{T_i}'][k]:\n",
    "                table_str += \"&\\\\textbf{\"+ f\"{round(val_KLD_dicts[f'{T_i}'][k],magnitude)}$\\pm${round(error_val_KLD_dicts[f'{T_i}'][k],magnitude)}\"+\"}\"\n",
    "            else:\n",
    "                table_str += f\"&{round(val_KLD_dicts[f'{T_i}'][k],magnitude)}$\\pm${round(error_val_KLD_dicts[f'{T_i}'][k],magnitude)}\"\n",
    "\n",
    "        table_str += \"\\\\\\\\\\n\"\n",
    "    table_str += \"\\hline\\n\"\n",
    "\n",
    "    table_str = table_str +\"\\end{tabularx}\"\n",
    "    print(f\"%subtable {c+1}\")\n",
    "    print(table_str)\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the densities\n",
    "\n",
    "---\n",
    "\n",
    "Best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = \"jet\"\n",
    "lim_list_grid = [[-9,9],[-9,9]]\n",
    "res_list_grid = [500,500]\n",
    "fs = 35\n",
    "T_list_plotting = [0.20691,0.54556,1.0,1.83298,4.83293]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INN_dict_last_cp = {}\n",
    "\n",
    "for key in base_paths_dict:\n",
    "\n",
    "    INN_last_i,_ = load_INN(base_path = base_paths_dict[key],use_last = False)\n",
    "\n",
    "    INN_dict_last_cp[key] = INN_last_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(len(base_paths_dict.keys())+1,len(T_list_plotting),figsize = (len(T_list_plotting) * 5,(1 +len(base_paths_dict.keys())) * 5))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i,T_i in enumerate(T_list_plotting):\n",
    "\n",
    "        #Ground truth distribution\n",
    "        p = partial(p_beta,gmm = gmm,beta = 1 / T_i, Z = Z_T_dict[f\"{T_i}\"])\n",
    "\n",
    "        pdf_grid,x_grid,y_grid = eval_pdf_on_grid_2D(\n",
    "            pdf=p,\n",
    "            x_lims = lim_list_grid[0],\n",
    "            y_lims = lim_list_grid[1],\n",
    "            x_res = res_list_grid[0],\n",
    "            y_res = res_list_grid[1],\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        grid_dict_i = {\"gt\":pdf_grid.detach().cpu()}\n",
    "        min_val = pdf_grid.min()\n",
    "        max_val = pdf_grid.max()\n",
    "\n",
    "        for k in base_paths_dict:\n",
    "\n",
    "            p_k = partial(INN_dict_last_cp[k].log_prob,beta_tensor = 1 / T_i)\n",
    "            pdf_grid_k,x_grid,y_grid = eval_pdf_on_grid_2D(\n",
    "                pdf=p_k,\n",
    "                x_lims = lim_list_grid[0],\n",
    "                y_lims = lim_list_grid[1],\n",
    "                x_res = res_list_grid[0],\n",
    "                y_res = res_list_grid[1],\n",
    "                device = device\n",
    "            )\n",
    "\n",
    "            pdf_grid_k = pdf_grid_k.detach().cpu().exp()\n",
    "\n",
    "            grid_dict_i[k] = pdf_grid_k\n",
    "\n",
    "            if min_val > pdf_grid_k.min():\n",
    "                min_val = pdf_grid_k.min()\n",
    "\n",
    "            if max_val < pdf_grid_k.max():\n",
    "                max_val = pdf_grid_k.max()\n",
    "\n",
    "        axes[0][i].set_title(f\"c = {round(1 / T_i,4)}\",fontsize = fs)\n",
    "        for j,k in enumerate(grid_dict_i.keys()):\n",
    "\n",
    "            axes[j][i].imshow(\n",
    "                grid_dict_i[k],\n",
    "                extent = [x_grid.detach().cpu().min(),\n",
    "                x_grid.detach().cpu().max(),\n",
    "                y_grid.detach().cpu().min(),\n",
    "                y_grid.detach().cpu().max()],\n",
    "                origin = 'lower',\n",
    "                #vmin = min_val,\n",
    "                #vmax = max_val,\n",
    "                cmap = cmap\n",
    "                )\n",
    "\n",
    "            axes[j][i].set(yticklabels=[])  # remove the tick labels\n",
    "            axes[j][i].tick_params(left=False)\n",
    "\n",
    "            axes[j][i].set(xticklabels=[])  # remove the tick labels\n",
    "            axes[j][i].tick_params(bottom=False)\n",
    "\n",
    "            if i == 0:\n",
    "                axes[j][0].set_ylabel(row_name_dict[k],fontsize = fs)\n",
    "\n",
    "            #Label\n",
    "            axes[j][i].text(-8.5,7.0, f\"{chr(ord('A') + j)}{i+1}\", fontsize = fs,c = \"w\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"densities_2D_GMM_best.pdf\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model at the end of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INN_dict_last_cp = {}\n",
    "\n",
    "for key in base_paths_dict:\n",
    "\n",
    "    INN_last_i,_ = load_INN(base_path = base_paths_dict[key],use_last = True)\n",
    "\n",
    "    INN_dict_last_cp[key] = INN_last_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(len(base_paths_dict.keys())+1,len(T_list_plotting),figsize = (len(T_list_plotting) * 5,(1 +len(base_paths_dict.keys())) * 5))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i,T_i in enumerate(T_list_plotting):\n",
    "\n",
    "        #Ground truth distribution\n",
    "        p = partial(p_beta,gmm = gmm,beta = 1 / T_i, Z = Z_T_dict[f\"{T_i}\"])\n",
    "\n",
    "        pdf_grid,x_grid,y_grid = eval_pdf_on_grid_2D(\n",
    "            pdf=p,\n",
    "            x_lims = lim_list_grid[0],\n",
    "            y_lims = lim_list_grid[1],\n",
    "            x_res = res_list_grid[0],\n",
    "            y_res = res_list_grid[1],\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        grid_dict_i = {\"gt\":pdf_grid.detach().cpu()}\n",
    "        min_val = pdf_grid.min()\n",
    "        max_val = pdf_grid.max()\n",
    "\n",
    "        for k in base_paths_dict:\n",
    "\n",
    "            p_k = partial(INN_dict_last_cp[k].log_prob,beta_tensor = 1 / T_i)\n",
    "            pdf_grid_k,x_grid,y_grid = eval_pdf_on_grid_2D(\n",
    "                pdf=p_k,\n",
    "                x_lims = lim_list_grid[0],\n",
    "                y_lims = lim_list_grid[1],\n",
    "                x_res = res_list_grid[0],\n",
    "                y_res = res_list_grid[1],\n",
    "                device = device\n",
    "            )\n",
    "\n",
    "            pdf_grid_k = pdf_grid_k.detach().cpu().exp()\n",
    "\n",
    "            grid_dict_i[k] = pdf_grid_k\n",
    "\n",
    "            if min_val > pdf_grid_k.min():\n",
    "                min_val = pdf_grid_k.min()\n",
    "\n",
    "            if max_val < pdf_grid_k.max():\n",
    "                max_val = pdf_grid_k.max()\n",
    "\n",
    "        axes[0][i].set_title(f\"c = {round(1 / T_i,4)}\",fontsize = fs)\n",
    "        for j,k in enumerate(grid_dict_i.keys()):\n",
    "\n",
    "            axes[j][i].imshow(\n",
    "                grid_dict_i[k],\n",
    "                extent = [x_grid.detach().cpu().min(),\n",
    "                x_grid.detach().cpu().max(),\n",
    "                y_grid.detach().cpu().min(),\n",
    "                y_grid.detach().cpu().max()],\n",
    "                origin = 'lower',\n",
    "                #vmin = min_val,\n",
    "                #vmax = max_val,\n",
    "                cmap = cmap\n",
    "                )\n",
    "\n",
    "            axes[j][i].set(yticklabels=[])  # remove the tick labels\n",
    "            axes[j][i].tick_params(left=False)\n",
    "\n",
    "            axes[j][i].set(xticklabels=[])  # remove the tick labels\n",
    "            axes[j][i].tick_params(bottom=False)\n",
    "\n",
    "            if i == 0:\n",
    "                axes[j][0].set_ylabel(row_name_dict[k],fontsize = fs)\n",
    "\n",
    "            #Label\n",
    "            axes[j][i].text(-8.5,7.0, f\"{chr(ord('A') + j)}{i+1}\", fontsize = fs,c = \"w\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"densities_2D_GMM_final.pdf\")\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
