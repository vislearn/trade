{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768931ae-2bca-451a-a883-8e4171887f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad3350-1191-425f-aa59-ec1603661c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from trade import BoltzmannGeneratorHParams, BoltzmannGenerator\n",
    "import torch\n",
    "import numpy as np\n",
    "from math import ceil, floor\n",
    "from yaml import safe_load\n",
    "import os\n",
    "from functools import partial\n",
    "import mdtraj as md\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib\n",
    "from trade.data import get_loader\n",
    "import pandas as pd\n",
    "from tqdm.auto import trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed247e69-8249-452e-af89-4363de7f1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6dc0d7-bdb6-42cd-ab81-1625019fc87a",
   "metadata": {},
   "source": [
    "## Plots and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c9abbc-47ed-4aea-954e-a712c7acda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kl_divergence(data_model, data_ground_truth, bins=50, range=None):\n",
    "    \"\"\"\n",
    "    Compute the KL divergence between two 2D histograms of model and ground truth data.\n",
    "\n",
    "    Parameters:\n",
    "        data_model (array-like): Nx2 array of model data points.\n",
    "        data_ground_truth (array-like): Nx2 array of ground truth data points.\n",
    "        bins (int or tuple of ints): Number of bins along each dimension.\n",
    "        range (array-like, optional): Range of the bins [(xmin, xmax), (ymin, ymax)].\n",
    "                                      If None, inferred from the data.\n",
    "\n",
    "    Returns:\n",
    "        float: KL divergence between the two histograms.\n",
    "    \"\"\"\n",
    "    # Compute 2D histograms\n",
    "    hist_model, xedges, yedges = np.histogram2d(\n",
    "        data_model[:, 0], data_model[:, 1], bins=bins, range=range\n",
    "    )\n",
    "    hist_ground_truth, _, _ = np.histogram2d(\n",
    "        data_ground_truth[:, 0], data_ground_truth[:, 1], bins=bins, range=range\n",
    "    )\n",
    "\n",
    "    # Normalize histograms to get probability distributions\n",
    "    P = hist_model / np.sum(hist_model)\n",
    "    Q = hist_ground_truth / np.sum(hist_ground_truth)\n",
    "\n",
    "    # Avoid log(0) or division by zero: set invalid entries to 0\n",
    "    mask = (P > 0) & (Q > 0)\n",
    "    P = P[mask]\n",
    "    Q = Q[mask]\n",
    "\n",
    "    # Compute KL divergence\n",
    "    kl_divergence = np.sum(P * np.log(P / Q))\n",
    "\n",
    "    return kl_divergence\n",
    "\n",
    "def get_angles(samples, system):\n",
    "    try:\n",
    "        samples = samples.cpu()\n",
    "    except:\n",
    "        pass\n",
    "    trajectory = md.Trajectory(\n",
    "        xyz=samples.reshape(-1, 22, 3), \n",
    "        topology=system.mdtraj_topology\n",
    "    )\n",
    "    return np.stack(system.compute_phi_psi(trajectory), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02a48e-5a50-4d4d-9643-f92438b0c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def plot_ala2(samples, system, target_energy, reference_data=None):\n",
    "    has_reference = reference_data is not None\n",
    "    fig, ax = plt.subplots(1, 3 + has_reference, figsize=(5*(3 + has_reference), 5))\n",
    "    plot_energies(ax[2+has_reference], samples, target_energy, reference_data)\n",
    "    ax[-1].set_title(\"Energy distribution\")\n",
    "\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "    if has_reference:\n",
    "        reference_data = reference_data.cpu().detach().numpy()\n",
    "        vmin, vmax = plot_phi_psi(ax[1], reference_data, system)\n",
    "        ax[1].set_title(\"Ramachandran plot (MD)\")\n",
    "    else:\n",
    "        vmin, vmax = None, None\n",
    "    plot_phi_psi(ax[0], samples, system, vmin=vmin, vmax=vmax)\n",
    "    ax[0].set_title(\"Ramachandran plot (BG)\")\n",
    "\n",
    "    plot_phi(ax[1+has_reference], samples, system, reference_data)\n",
    "    ax[1+has_reference].set_title(f\"Density of $\\\\phi$\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def plot_ala2_together(*samples, system, target_energy, reference_data=None, names=None):\n",
    "    if names is None:\n",
    "        names = [f\"model {i}\" for i in range(len(samples))]\n",
    "    has_reference = reference_data is not None\n",
    "    fig, ax = plt.subplots(1, 2 + has_reference + len(samples), figsize=(5*(2 + has_reference + len(samples)), 5))\n",
    "    plot_energies(ax[-1], *samples, target_energy=target_energy, test_data=reference_data, names=names)\n",
    "    ax[-1].set_title(\"Energy distribution\")\n",
    "\n",
    "\n",
    "\n",
    "    plot_phi(ax[-2], *samples, system=system, reference_data=reference_data, names=names)\n",
    "    ax[-2].set_title(f\"Density of $\\\\phi$\")\n",
    "\n",
    "    if has_reference:\n",
    "        reference_data = reference_data.cpu().detach().numpy()\n",
    "        vmin, vmax = plot_phi_psi(ax[-3], reference_data, system)\n",
    "        ax[2].set_title(\"Ramachandran plot (MD)\")\n",
    "    else:\n",
    "        vmin, vmax = None, None\n",
    "\n",
    "    for i, (name, sample) in enumerate(zip(names, samples)):\n",
    "        sample = sample.cpu().detach().numpy()\n",
    "        plot_phi_psi(ax[i], sample, system, vmin=vmin, vmax=vmax)\n",
    "        ax[i].set_title(f\"Ramachandran plot ({name})\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_phi_psi(ax, trajectory, system, vmin=None, vmax=None):\n",
    "    try:\n",
    "        trajectory = trajectory.cpu()\n",
    "    except:\n",
    "        pass\n",
    "    if not isinstance(trajectory, md.Trajectory):\n",
    "        trajectory = md.Trajectory(\n",
    "            xyz=trajectory.reshape(-1, 22, 3), \n",
    "            topology=system.mdtraj_topology\n",
    "        )\n",
    "    phi, psi = system.compute_phi_psi(trajectory)\n",
    "    hist = ax.hist2d(phi, psi, 50, norm=LogNorm(vmin=vmin, vmax=vmax), density=True)\n",
    "    ax.set_xlim(-np.pi, np.pi)\n",
    "    ax.set_ylim(-np.pi, np.pi)\n",
    "    ax.set_xlabel(\"$\\phi$\")\n",
    "    ax.set_ylabel(\"$\\psi$\")\n",
    "    \n",
    "    return hist[-1].get_clim()\n",
    "\n",
    "def plot_energies(ax, *samples, target_energy=None, test_data=None, names=None):\n",
    "\n",
    "    samples_energy = []\n",
    "    min_energy = np.inf\n",
    "    max_energy = - np.inf\n",
    "    cut = -np.inf\n",
    "    for sample in samples:\n",
    "        samples_energy.append(target_energy(sample).cpu().detach().numpy())\n",
    "        min_s, max_s = np.nanmin(samples_energy[-1]), np.nanmax(samples_energy[-1])\n",
    "        min_energy, max_energy = min(min_s, min_energy), max(max_s, max_energy)\n",
    "        cut = max(np.nanpercentile(samples_energy[-1], 80), cut)\n",
    "    if test_data is not None:\n",
    "        md_energies = target_energy(test_data[:len(samples[0])]).cpu().detach().numpy()\n",
    "        min_s, max_s = np.nanmin(md_energies), np.nanmax(md_energies)\n",
    "        min_energy, max_energy = min(min_s, min_energy), max(max_s, max_energy)\n",
    "        cut = max(np.nanmax(md_energies), cut)\n",
    "    else:\n",
    "        md_energies = sample_energies\n",
    "    full_range = min_energy, max_energy\n",
    "    plot_range = (full_range[0] - 0.1*(cut - full_range[0]), cut)\n",
    "\n",
    "    ax.set_xlabel(\"Energy   [$k_B T$]\")\n",
    "    # y-axis on the right\n",
    "    ax2 = plt.twinx(ax)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    \n",
    "    if test_data is not None:\n",
    "\n",
    "        count_md_energies = np.sum(np.logical_and(md_energies < plot_range[1], md_energies > plot_range[0]))\n",
    "        \n",
    "        for name, sample_energy in zip(names, samples_energy):\n",
    "            # This adjusts the counts to be comparable, even if different number of samples fall into the range\n",
    "            count_sample_energy = np.sum(np.logical_and(sample_energy < plot_range[1], sample_energy > plot_range[0]))\n",
    "            weights_sample = np.ones_like(sample_energy)*count_md_energies/count_sample_energy\n",
    "\n",
    "            ax2.hist(sample_energy, range=plot_range, bins=40, weights=weights_sample, density=False, label=f\"{name}\", alpha=0.6)\n",
    "    else:\n",
    "        for name, sample_energy in zip(names, samples_energy):\n",
    "            ax2.hist(sample_energy, range=plot_range, bins=40, density=False, label=f\"{name}\", alpha=0.6)\n",
    "\n",
    "    if test_data is not None:\n",
    "        ax2.hist(md_energies, range=plot_range, bins=40, density=False, label=\"MD\", alpha=0.3)\n",
    "    ax2.set_ylabel(f\"Count   [#Samples / {len(samples)}]\")\n",
    "    ax2.legend()\n",
    "\n",
    "def plot_phi(ax, *trajectories, system=None, reference_data=None, names=None):\n",
    "    for name, trajectory in zip(names, trajectories):\n",
    "        try:\n",
    "            trajectory = trajectory.cpu()\n",
    "        except:\n",
    "            pass\n",
    "        if not isinstance(trajectory, md.Trajectory):\n",
    "            trajectory = md.Trajectory(\n",
    "                xyz=trajectory.reshape(-1, 22, 3), \n",
    "                topology=system.mdtraj_topology\n",
    "            )\n",
    "\n",
    "        phi, _ = system.compute_phi_psi(trajectory)\n",
    "        p_phi = np.histogram(phi, bins=100, range=(-np.pi, np.pi), density=True)\n",
    "        ax.plot(p_phi[1][:-1], p_phi[0], label=f\"{name}\")\n",
    "\n",
    "    if reference_data is not None:\n",
    "        reference_data = md.Trajectory(\n",
    "            xyz=reference_data.reshape(-1, 22, 3), \n",
    "            topology=system.mdtraj_topology\n",
    "        )\n",
    "        phi_ref, _ = system.compute_phi_psi(reference_data)\n",
    "        p_phi_ref = np.histogram(phi_ref, bins=100, range=(-np.pi, np.pi), density=True)\n",
    "        ax.plot(p_phi_ref[1][:-1], p_phi_ref[0], label=\"MD\")\n",
    "\n",
    "    ax.set_xlim(-np.pi, np.pi)\n",
    "    ax.set_xlabel(\"$\\phi$\")\n",
    "    ax.set_ylabel(\"$p(\\phi)$\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab77738-aed4-41d5-a8eb-0037d6777b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def ESS_from_log_weights(log_omega, clip_weights=False):\n",
    "    log_omega = log_omega - torch.logsumexp(log_omega, dim=0)\n",
    "    log_a = 2 * torch.logsumexp(log_omega,0)\n",
    "    log_b = torch.logsumexp(2 * log_omega,0)\n",
    "\n",
    "    ESS_r = torch.exp(log_a - log_b - np.log(len(log_omega)))\n",
    "    return ESS_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df82d5b-25b3-47c1-a8fb-ce8b14ea3fd4",
   "metadata": {},
   "source": [
    "## TRADE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd0de4-d672-4975-8658-9ffb03a76bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"lightning_logs/version_\" # Path to your trained model\n",
    "\n",
    "hparams_path = os.path.join(model_folder, \"hparams.yaml\")\n",
    "checkpoint_path = os.path.join(model_folder, \"checkpoints/last.ckpt\")\n",
    "\n",
    "ckpt = torch.load(checkpoint_path)\n",
    "hparams_trade = dict(ckpt[\"hyper_parameters\"])\n",
    "del hparams_trade[\"n_steps\"]\n",
    "del hparams_trade[\"epoch_len\"]\n",
    "model_trade = BoltzmannGenerator(hparams_trade)\n",
    "model_trade.load_state_dict(ckpt[\"state_dict\"])\n",
    "model_trade.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb08a3-4f1d-4fa5-b3c7-e61872fe7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = model_trade.datasets[0].system\n",
    "batch_size = 10000\n",
    "model_trade = model_trade.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3d6b3-946a-4082-a364-473e0813a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data_trade = model_trade.val_data[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03f138-3283-4844-9872-7e2c2202f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "with torch.no_grad():\n",
    "    samples = []\n",
    "    log_weights = []\n",
    "    nll = []\n",
    "    for i in trange(ceil(len(reference_data_trade)/batch_size)):\n",
    "\n",
    "        x_gt, c_gt = reference_data_trade.split(batch_size)[i], []\n",
    "        nll.append(model_trade.flow.energy(x_gt.to(device), c_gt, parameter=T))\n",
    "        c = model_trade.sample_condition(batch_size=batch_size)\n",
    "        x = model_trade.flow.sample(batch_size, c=c, parameter=T)\n",
    "        lw = torch.zeros_like(x[:,0])\n",
    "        samples.append(x)\n",
    "        log_weights.append(lw)\n",
    "    \n",
    "    nll_trade = torch.cat(nll, dim=0).mean().item()\n",
    "    samples_trade = torch.cat(samples, dim=0)\n",
    "    log_weights = torch.cat(log_weights, dim=0)\n",
    "    ESS_trade = ESS_from_log_weights(log_weights).item()\n",
    "    model_angles = get_angles(samples_trade, system)\n",
    "    gt_angles = get_angles(reference_data_trade, system)\n",
    "    kl_divergence_angles = compute_kl_divergence(model_angles, gt_angles, bins=30) \n",
    "    print(f\"Effective Sample Size at T={T:.1f}: {ESS_trade*100:.2f}%\")\n",
    "    print(f\"Negative Log Likelihood at T={T:.1f}: {nll_trade:.2f}\")\n",
    "    print(f\"KL diveregence $\\phi, \\psi$ histogram at T={T:.1f}: {kl_divergence_angles:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe497b3-fd13-44d2-b665-50c2972d8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_loader(\"ala2\")(temperature=300)\n",
    "\n",
    "ind = torch.randperm(len(dataset.coordinates))[:len(reference_data_trade)]\n",
    "reference_data_low = torch.from_numpy(dataset.coordinates.reshape(-1, dataset.dim))[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab82c6-117a-4a70-998a-69f2bad2049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0.5\n",
    "with torch.no_grad():\n",
    "    samples = []\n",
    "    log_weights = []\n",
    "    nll = []\n",
    "    for i in trange(ceil(len(reference_data_low)/batch_size)):\n",
    "\n",
    "        x_gt, c_gt = reference_data_low.split(batch_size)[i], []\n",
    "        nll.append(model_trade.flow.energy(x_gt.to(device), c_gt, parameter=T))\n",
    "        c = model_trade.sample_condition(batch_size=batch_size)\n",
    "        x = model_trade.flow.sample(batch_size, c=c, parameter=T)\n",
    "        lw = torch.zeros_like(x[:,0])\n",
    "        samples.append(x)\n",
    "        log_weights.append(lw)\n",
    "    \n",
    "    nll_trade = torch.cat(nll, dim=0).mean().item()\n",
    "    samples_trade_lowT = torch.cat(samples, dim=0)\n",
    "    log_weights = torch.cat(log_weights, dim=0)\n",
    "    ESS_trade = ESS_from_log_weights(log_weights).item()\n",
    "    model_angles = get_angles(samples_trade_lowT, system)\n",
    "    gt_angles = get_angles(reference_data_low, system)\n",
    "    kl_divergence_angles = compute_kl_divergence(model_angles, gt_angles, bins=30) \n",
    "    print(f\"Effective Sample Size at T={T:.1f}: {ESS_trade*100:.2f}%\")\n",
    "    print(f\"Negative Log Likelihood at T={T:.1f}: {nll_trade:.2f}\")\n",
    "    print(f\"KL diveregence $\\phi, \\psi$ histogram at T={T:.1f}: {kl_divergence_angles:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ee45c-3bb7-4f46-8878-3179aab719e0",
   "metadata": {},
   "source": [
    "## Temperature Steerable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff90e6-0d2c-4f1f-af62-e5777c976c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"lightning_logs/version_\" # Path to your trained model\n",
    "\n",
    "hparams_path = os.path.join(model_folder, \"hparams.yaml\")\n",
    "checkpoint_path = os.path.join(model_folder, \"checkpoints/last.ckpt\")\n",
    "\n",
    "ckpt = torch.load(checkpoint_path)\n",
    "hparams_vp = dict(ckpt[\"hyper_parameters\"])\n",
    "del hparams_vp[\"n_steps\"]\n",
    "del hparams_vp[\"epoch_len\"]\n",
    "model_vp = BoltzmannGenerator(hparams_vp)\n",
    "model_vp.load_state_dict(ckpt[\"state_dict\"])\n",
    "model_vp.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e555eb-3e28-4d07-9a34-16572a41c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = model_vp.datasets[0].system\n",
    "batch_size = 10000\n",
    "model_trade = model_vp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f10466-70e5-443a-9d18-b2c959ddd431",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data_vp = model_vp.val_data[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199c7bf-71f7-45e8-8284-64a5b2fd4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "with torch.no_grad():\n",
    "    samples = []\n",
    "    log_weights = []\n",
    "    nll = []\n",
    "    for i in trange(ceil(len(reference_data_vp)/batch_size)):\n",
    "\n",
    "        x_gt, c_gt = reference_data_vp.split(batch_size)[i], []\n",
    "        nll.append(model_vp.flow.energy(x_gt.to(device), c_gt, parameter=T))\n",
    "\n",
    "        c = model_vp.sample_condition(batch_size=batch_size)\n",
    "        x = model_vp.flow.sample(batch_size, c=c, parameter=T)\n",
    "        samples.append(x)\n",
    "        lw = torch.zeros_like(x[:,0])\n",
    "        log_weights.append(lw)\n",
    "    \n",
    "    nll_vp = torch.cat(nll, dim=0).mean().item()\n",
    "    samples_vp = torch.cat(samples, dim=0)\n",
    "    log_weights = torch.cat(log_weights, dim=0)\n",
    "    ESS_vp = ESS_from_log_weights(log_weights).item()\n",
    "    model_angles = get_angles(samples_vp, system)\n",
    "    gt_angles = get_angles(reference_data_vp, system)\n",
    "    kl_divergence_angles = compute_kl_divergence(model_angles, gt_angles, bins=30) \n",
    "    print(f\"Effective Sample Size at T={T:.1f}: {ESS_vp*100:.2f}%\")\n",
    "    print(f\"Negative Log Likelihood at T={T:.1f}: {nll_vp:.2f}\")\n",
    "    print(f\"KL diveregence $\\phi, \\psi$ histogram at T={T:.1f}: {kl_divergence_angles:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d575018-803f-4d12-855d-180aea733311",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_loader(\"ala2\")(temperature=300)\n",
    "\n",
    "ind = torch.randperm(len(dataset.coordinates))[:len(reference_data_vp)]\n",
    "reference_data_low = torch.from_numpy(dataset.coordinates.reshape(-1, dataset.dim))[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9fdcc-3d2c-42da-94a6-13ef5c867545",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0.5\n",
    "with torch.no_grad():\n",
    "    samples = []\n",
    "    log_weights = []\n",
    "    nll = []\n",
    "    for i in trange(ceil(len(reference_data_low)/batch_size)):\n",
    "\n",
    "        x_gt, c_gt = reference_data_low.split(batch_size)[i], []\n",
    "        nll.append(model_vp.flow.energy(x_gt.to(device), c_gt, parameter=T))\n",
    "        \n",
    "\n",
    "        c = model_vp.sample_condition(batch_size=batch_size)\n",
    "        # x = fix_sampling_bg_vp(model_vp.flow.bgflow_bg, batch_size, context=c, temperature=T)\n",
    "        x = model_vp.flow.sample(batch_size, c=c, parameter=T)\n",
    "        samples.append(x)\n",
    "        lw = torch.zeros_like(x[:,0])\n",
    "        log_weights.append(lw)\n",
    "    \n",
    "    nll_vp = torch.cat(nll, dim=0).mean().item()\n",
    "    samples_vp_lowT = torch.cat(samples, dim=0)\n",
    "    log_weights = torch.cat(log_weights, dim=0)\n",
    "    ESS_vp = ESS_from_log_weights(log_weights).item()\n",
    "    model_angles = get_angles(samples_vp_lowT, system)\n",
    "    gt_angles = get_angles(reference_data_low, system)\n",
    "    kl_divergence_angles = compute_kl_divergence(model_angles, gt_angles, bins=30) \n",
    "    print(f\"Effective Sample Size at T={T:.1f}: {ESS_vp*100:.2f}%\")\n",
    "    print(f\"Negative Log Likelihood at T={T:.1f}: {nll_vp:.2f}\")\n",
    "    print(f\"KL diveregence $\\phi, \\psi$ histogram at T={T:.1f}: {kl_divergence_angles:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91dc24f-a5b9-4782-bee5-3e7c964bac34",
   "metadata": {},
   "source": [
    "## Reverse KL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e2e961-28dc-4c26-b1e1-addea39cee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"lightning_logs/version_\" # Path to your trained model\n",
    "\n",
    "hparams_path = os.path.join(model_folder, \"hparams.yaml\")\n",
    "checkpoint_path = os.path.join(model_folder, \"checkpoints/last.ckpt\")\n",
    "\n",
    "ckpt = torch.load(checkpoint_path)\n",
    "hparams_rev_kl = dict(ckpt[\"hyper_parameters\"])\n",
    "del hparams_rev_kl[\"n_steps\"]\n",
    "del hparams_rev_kl[\"epoch_len\"]\n",
    "model_rev_kl = BoltzmannGenerator(hparams_rev_kl)\n",
    "model_rev_kl.load_state_dict(ckpt[\"state_dict\"])\n",
    "model_rev_kl.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f7b4c9-0dda-4a44-b799-71a1e61b1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = model_rev_kl.datasets[0].system\n",
    "batch_size = 10000\n",
    "model_trade = model_rev_kl.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500cfb8-9502-48e6-aec6-1852b2be0778",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data_rev_kl = model_rev_kl.val_data[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e93429-0c61-4854-9bd7-9c8eb275c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "with torch.no_grad():\n",
    "    samples = []\n",
    "    log_weights = []\n",
    "    nll = []\n",
    "    for i in trange(ceil(len(reference_data_rev_kl)/batch_size)):\n",
    "\n",
    "        x_gt, c_gt = reference_data_rev_kl.split(batch_size)[i], []\n",
    "        nll.append(model_rev_kl.flow.energy(x_gt.to(device), c_gt, parameter=T))\n",
    "\n",
    "        c = model_rev_kl.sample_condition(batch_size=batch_size)\n",
    "        x = model_rev_kl.flow.sample(batch_size, c=c, parameter=T)\n",
    "        samples.append(x)\n",
    "        lw = torch.zeros_like(x[:,0])\n",
    "        log_weights.append(lw)\n",
    "    \n",
    "    nll_rev_kl = torch.cat(nll, dim=0).mean().item()\n",
    "    samples_rev_kl = torch.cat(samples, dim=0)\n",
    "    log_weights = torch.cat(log_weights, dim=0)\n",
    "    ESS_rev_kl = ESS_from_log_weights(log_weights).item()\n",
    "    model_angles = get_angles(samples_rev_kl, system)\n",
    "    gt_angles = get_angles(reference_data_rev_kl, system)\n",
    "    kl_divergence_angles = compute_kl_divergence(model_angles, gt_angles, bins=30) \n",
    "    print(f\"Effective Sample Size at T={T:.1f}: {ESS_rev_kl*100:.2f}%\")\n",
    "    print(f\"Negative Log Likelihood at T={T:.1f}: {nll_rev_kl:.2f}\")\n",
    "    print(f\"KL diveregence $\\phi, \\psi$ histogram at T={T:.1f}: {kl_divergence_angles:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8af3b-d8c6-4bf4-bec4-eabc62c376c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_loader(\"ala2\")(temperature=300)\n",
    "\n",
    "ind = torch.randperm(len(dataset.coordinates))[:len(reference_data_rev_kl)]\n",
    "reference_data_low = torch.from_numpy(dataset.coordinates.reshape(-1, dataset.dim))[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39b003-48b7-48e4-bfc8-9b768ccf4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0.5\n",
    "with torch.no_grad():\n",
    "    samples = []\n",
    "    log_weights = []\n",
    "    nll = []\n",
    "    for i in trange(ceil(len(reference_data_low)/batch_size)):\n",
    "\n",
    "        x_gt, c_gt = reference_data_low.split(batch_size)[i], []\n",
    "        nll.append(model_rev_kl.flow.energy(x_gt.to(device), c_gt, parameter=T))\n",
    "\n",
    "        c = model_rev_kl.sample_condition(batch_size=batch_size)\n",
    "        x = model_rev_kl.flow.sample(batch_size, c=c, parameter=T)\n",
    "        samples.append(x)\n",
    "        lw = torch.zeros_like(x[:,0])\n",
    "        log_weights.append(lw)\n",
    "    \n",
    "    nll_rev_kl = torch.cat(nll, dim=0).mean().item()\n",
    "    samples_rev_kl_lowT = torch.cat(samples, dim=0)\n",
    "    log_weights = torch.cat(log_weights, dim=0)\n",
    "    ESS_rev_kl = ESS_from_log_weights(log_weights).item()\n",
    "    model_angles = get_angles(samples_rev_kl_lowT, system)\n",
    "    gt_angles = get_angles(reference_data_low, system)\n",
    "    kl_divergence_angles = compute_kl_divergence(model_angles, gt_angles, bins=30) \n",
    "    print(f\"Effective Sample Size at T={T:.1f}: {ESS_rev_kl*100:.2f}%\")\n",
    "    print(f\"Negative Log Likelihood at T={T:.1f}: {nll_rev_kl:.2f}\")\n",
    "    print(f\"KL diveregence $\\phi, \\psi$ histogram at T={T:.1f}: {kl_divergence_angles:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c048fd47-dabc-4411-9eff-b2480a6872a3",
   "metadata": {},
   "source": [
    "## Combined Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bde3ea-bfaf-49c5-89c4-e7b8c5d8e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ala2_together(samples_vp, \n",
    "                   samples_rev_kl, \n",
    "                   samples_trade, \n",
    "                   reference_data=reference_data_trade, \n",
    "                   system=system, \n",
    "                   target_energy=partial(model_trade.flow.get_energy_model().energy, \n",
    "                                         temperature=600),\n",
    "                   names=[\"TSF\", \"Rev KL\", \"TRADE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa7900-ff15-40af-a152-ac002936a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ala2_together(samples_vp_lowT, \n",
    "                   samples_rev_kl_lowT, \n",
    "                   samples_trade_lowT, \n",
    "                   reference_data=reference_data_low, \n",
    "                   system=system, \n",
    "                   target_energy=partial(model_trade.flow.get_energy_model().energy, \n",
    "                                         temperature=300),\n",
    "                   names=[\"TSF\", \"Rev KL\", \"TRADE\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
