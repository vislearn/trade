{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from trade.models import set_up_sequence_INN_ScalarTheory\n",
    "\n",
    "from trade.datasets import (\n",
    "    ActionScalarTheory\n",
    "    )\n",
    "\n",
    "from trade.plots import (\n",
    "    get_susceptibility,\n",
    "    get_U_L,\n",
    "    bootstrap\n",
    ")\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the trained Models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dict = {\n",
    "    \"NLL\":\"../results/runs_ScalarTheory/Path to your trained model/lightning_logs/version_0/\",\n",
    "    \"TRADE_grid\":\"../results/runs_ScalarTheory/Path to your trained modellightning_logs/version_0/\",\n",
    "    \"reverse_KL_NLL\":\"../results/runs_ScalarTheory/Path to your trained model/lightning_logs/version_0/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_folder(folder,device):\n",
    "\n",
    "    config_i = yaml.safe_load(Path(folder + \"/hparams.yaml\").read_text())\n",
    "    state_dict_folder_i = folder + f\"/checkpoints/\"\n",
    "\n",
    "    files = os.listdir(state_dict_folder_i)\n",
    "    state_dict_path_i = os.path.join(state_dict_folder_i,files[0])\n",
    "\n",
    "    config_i[\"device\"] = device\n",
    "\n",
    "    INN_i = set_up_sequence_INN_ScalarTheory(config=config_i)\n",
    "    INN_i.load_state_dict(state_dict_path_i)\n",
    "    INN_i.train(False)\n",
    "\n",
    "    return INN_i,config_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INN_dict = {}\n",
    "config_dict = {}\n",
    "\n",
    "for key in path_dict:\n",
    "    INN_key,config_key = load_model_from_folder(\n",
    "        folder = path_dict[key],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    INN_dict[key] = INN_key\n",
    "    config_dict[key] = config_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the reference simulation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reference simulation\n",
    "reference = np.loadtxt(\"../data/ScalarTheory/validation_data/N_8_LANGEVIN_SPECIFIC/summary_lambda_0.02_0.txt\",skiprows = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physical obervables\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kappas = 200\n",
    "n_samples_phyiscs = 10000\n",
    "bs_physics = 2000\n",
    "\n",
    "with torch.no_grad():\n",
    "    for key in INN_dict.keys():\n",
    "\n",
    "        kappas_phyiscs = np.linspace(config_dict[key][\"config_evaluation\"][\"kappa_physics_specs\"][0],config_dict[key][\"config_evaluation\"][\"kappa_physics_specs\"][1],n_kappas)\n",
    "        lambda_physics = np.arange(config_dict[key][\"config_evaluation\"][\"lambda_physics_specs\"][0],config_dict[key][\"config_evaluation\"][\"lambda_physics_specs\"][1],config_dict[key][\"config_evaluation\"][\"lambda_physics_specs\"][2])\n",
    "\n",
    "        if len(lambda_physics) > 1:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        output_file_i = f\"./summary_phyiscs_properties_lambda_{lambda_physics[0]}_{key}.txt\"\n",
    "        if os.path.exists(output_file_i):\n",
    "            continue\n",
    "\n",
    "        n_batches_phyiscs = int(n_samples_phyiscs / bs_physics)\n",
    "\n",
    "        magnetizations_i = torch.zeros([len(kappas_phyiscs),2])\n",
    "        actions_gt_i = torch.zeros([len(kappas_phyiscs),2])\n",
    "        susceptibility_i = torch.zeros([len(kappas_phyiscs),2])\n",
    "        binder_cumulant_i = torch.zeros([len(kappas_phyiscs),2])\n",
    "\n",
    "    \n",
    "        counter = 0\n",
    "\n",
    "        for k in tqdm.tqdm(kappas_phyiscs):\n",
    "            for l in lambda_physics:\n",
    "\n",
    "                actions_gt_kl_u = torch.zeros([0])\n",
    "                magnetization_kl_u = torch.zeros([0])\n",
    "\n",
    "                for i in range(n_batches_phyiscs):\n",
    "                    with torch.no_grad():\n",
    "                        samples_kli_u = INN_dict[key].sample(n_samples = bs_physics,beta_tensor = k).cpu().detach()\n",
    "\n",
    "                        action_gt_kli_u = ActionScalarTheory(samples_kli_u,k,l)\n",
    "                        magnetization_kli_u = samples_kli_u.sum(dim = (1,2,3))\n",
    "\n",
    "                    actions_gt_kl_u = torch.cat((actions_gt_kl_u,action_gt_kli_u),0)\n",
    "                    magnetization_kl_u = torch.cat((magnetization_kl_u,magnetization_kli_u),0)\n",
    "\n",
    "                N = config_dict[key][\"config_data\"][\"N\"]\n",
    "\n",
    "                mean_magnetization,std_magnetization = bootstrap(x = np.abs(np.array(magnetization_kl_u)) / N**2,s = np.mean,args={\"axis\":0})\n",
    "                mean_action_gt,std_action_gt = bootstrap(x = np.array(actions_gt_kl_u) / N**2,s = np.mean,args={\"axis\":0})\n",
    "                susceptibility_mean,sigma_susceptibility = bootstrap(x = np.abs(np.array(magnetization_kl_u)),s = get_susceptibility,args={\"Omega\":N**2})\n",
    "                U_L_mean,sigma_U_L = bootstrap(x = np.array(magnetization_kl_u),s = get_U_L,args={\"Omega\":N**2})\n",
    "\n",
    "                magnetizations_i[counter] = torch.Tensor([mean_magnetization,std_magnetization])\n",
    "                actions_gt_i[counter] = torch.Tensor([mean_action_gt,std_action_gt])\n",
    "                susceptibility_i[counter] = torch.Tensor([susceptibility_mean,sigma_susceptibility])\n",
    "                binder_cumulant_i[counter] = torch.Tensor([U_L_mean,sigma_U_L])\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "        #Save the results as a text file. Write the infirmation in the following order: kappa, magnetization, action, susceptibility, binder cumulant and add it to the header\n",
    "        header = \"kappa,mean_magnetization,std_magnetization,mean_action_gt,std_action_gt,susceptibility_mean,sigma_susceptibility,U_L_mean,sigma_U_L\"\n",
    "        data = np.concatenate((kappas_phyiscs[:,np.newaxis],magnetizations_i,actions_gt_i,susceptibility_i,binder_cumulant_i),axis = 1)\n",
    "        np.savetxt(output_file_i,data,header = header,comments = \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"C1\",\"C3\",\"C6\"]\n",
    "\n",
    "labels = [\"A\",\"B\",\"C\",\"D\"]\n",
    "ylabels = [r\"$\\left<|m|\\right>$\",r\"$\\left<s\\right>$\",r\"$\\chi^2$\",r\"$U_L$\"]\n",
    "\n",
    "fs = 27\n",
    "lw = 4\n",
    "\n",
    "tags = {\n",
    "    \"TRADE_grid\":\"TRADE\",\n",
    "    \"reverse_KL_NLL\":\"reverse KL + NLL\",\n",
    "    \"NLL\":\"NLL\"\n",
    "}\n",
    "\n",
    "reference_properties = [\n",
    "    reference[:,1:3],\n",
    "    reference[:,3:5],\n",
    "    reference[:,7:9],\n",
    "    reference[:,5:7]\n",
    "]\n",
    "\n",
    "y_lims = [\n",
    "    [0.0,4.0],\n",
    "    [-3,1.2],\n",
    "    [-0.5,15],\n",
    "    [-0.1,0.9]\n",
    "]\n",
    "\n",
    "fig_physics,ax = plt.subplots(2,2,figsize = (15,8))\n",
    "\n",
    "#Get the properties from the saved tex files\n",
    "properties_dict = {}\n",
    "colors_dict = {}\n",
    "c = 0\n",
    "\n",
    "for key in INN_dict.keys():\n",
    "\n",
    "    print(f\"load data for {key}\")\n",
    "    data_u = np.loadtxt(f\"./summary_phyiscs_properties_lambda_{lambda_physics[0]}_{key}.txt\",skiprows = 1)\n",
    "\n",
    "    magnetizations_i = torch.Tensor(data_u[:,1:3])\n",
    "    actions_gt_i = torch.Tensor(data_u[:,3:5])\n",
    "    susceptibility_i = torch.Tensor(data_u[:,5:7])\n",
    "    binder_cumulant_i = torch.Tensor(data_u[:,7:9])\n",
    "\n",
    "    properties_dict[key] = [data_u[:,0],magnetizations_i,actions_gt_i,susceptibility_i,binder_cumulant_i]\n",
    "    colors_dict[key] = colors[c]\n",
    "    c += 1\n",
    "\n",
    "c = 1\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "\n",
    "        ax[i][j].plot(reference[:,0],reference_properties[c-1][:,0],ls = \"dotted\",color = \"k\",label = \"MCMC\",lw = 1.5 * lw)\n",
    "\n",
    "        for key in INN_dict.keys():\n",
    "            \n",
    "            ax[i][j].plot(properties_dict[key][0],properties_dict[key][c][:,0],ls = \"-\",color = colors_dict[key],label = tags[key],lw = lw)\n",
    "\n",
    "            #Plot a marker at the position where the training data was located\n",
    "            for base_param in config_dict[key][\"config_data\"][\"init_data_set_params\"][\"kappa_list\"]:\n",
    "\n",
    "                #Interpolate betewwn the two closest points on the grid\n",
    "                idx = np.argmin(np.abs(properties_dict[key][0] - base_param))\n",
    "                ax[i][j].plot(properties_dict[key][0][idx],properties_dict[key][c][idx,0],ls = \"\",marker = \"o\",markersize = 10, color = colors_dict[key])\n",
    "\n",
    "\n",
    "        ax[i][j].set_ylim(bottom = y_lims[c-1][0],top = y_lims[c-1][1])\n",
    "        ax[i][j].set_xlabel(r\"$\\kappa$\",fontsize = fs)\n",
    "        ax[i][j].set_ylabel(ylabels[c-1],fontsize = fs)\n",
    "        ax[i][j].set_title(labels[c-1],fontsize = fs)\n",
    "\n",
    "        c += 1\n",
    "\n",
    "        ax[i][j].tick_params(axis='both', which='major', labelsize=fs)\n",
    "\n",
    "handles, labels = [], []\n",
    "\n",
    "for handle, label in zip(*ax[0][0].get_legend_handles_labels()):\n",
    "    handles.append(handle)\n",
    "    labels.append(label)\n",
    "\n",
    "# Add a single legend below all subplots\n",
    "fig_physics.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.05), ncol=4,fontsize = fs)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"ScalarTheory_properties.pdf\",bbox_inches = \"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effective sampling size\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ESS(INN,n_sampels_ESS = 10000,bs_ESS = 2000,config = None,n_kappas = 200):\n",
    "    n_batches_ESS = int(n_sampels_ESS / bs_ESS)\n",
    "\n",
    "    kappa_ESS = np.linspace(config[\"config_evaluation\"][\"kappa_physics_specs\"][0],config[\"config_evaluation\"][\"kappa_physics_specs\"][1],n_kappas)\n",
    "    lambda_ESS = np.arange(config[\"config_evaluation\"][\"lambda_physics_specs\"][0],config[\"config_evaluation\"][\"lambda_physics_specs\"][1],config[\"config_evaluation\"][\"lambda_physics_specs\"][2])\n",
    "\n",
    "    if len(lambda_ESS) > 1:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    ESS_r_list_i = np.zeros(len(kappa_ESS))\n",
    "\n",
    "    for i,k in tqdm.tqdm(enumerate(kappa_ESS)):\n",
    "        for l in lambda_ESS:\n",
    "\n",
    "            log_p_target_INN = torch.zeros([0])\n",
    "            log_p_theta_INN = torch.zeros([0])\n",
    "\n",
    "            for j in range(n_batches_ESS):\n",
    "\n",
    "                #Compute the log likelihood of the INN samples\n",
    "                samples_i = INN.sample(n_samples = bs_ESS,beta_tensor = k)\n",
    "\n",
    "                log_p_theta_INN_i = INN.log_prob(samples_i,k).cpu()\n",
    "                log_p_theta_INN = torch.cat((log_p_theta_INN,log_p_theta_INN_i.detach().cpu()),0)\n",
    "\n",
    "                log_p_target_INN_i = - ActionScalarTheory(samples_i.cpu(),kappas = k,lambdas = l).cpu()\n",
    "                log_p_target_INN = torch.cat((log_p_target_INN,log_p_target_INN_i.detach().cpu()),0)\n",
    "\n",
    "            #Compuete the relative Kish effective sample size\n",
    "            log_omega = log_p_target_INN - log_p_theta_INN\n",
    "            log_a = 2 * torch.logsumexp(log_omega,0)\n",
    "            log_b = torch.logsumexp(2 * log_omega,0)\n",
    "\n",
    "            ESS_r = torch.exp(log_a - log_b) / len(log_omega)\n",
    "            ESS_r_list_i[i] = ESS_r\n",
    "\n",
    "    return ESS_r_list_i,kappa_ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in INN_dict.keys():\n",
    "\n",
    "    output_file_i = f\"./summary_ESS_lambda_{lambda_physics[0]}_{key}.txt\"\n",
    "\n",
    "    if os.path.exists(output_file_i):\n",
    "        continue\n",
    "    \n",
    "    ESS_r_list_i,kappa_ESS_i = get_ESS(INN = INN_dict[key],config=config_dict[key])\n",
    "            \n",
    "    #Save the results as a text file. Write the infirmation in the following order: kappa, magnetization, action, susceptibility, binder cumulant and add it to the header\n",
    "    header = \"kappa,ESS_r\"\n",
    "    data = np.concatenate((kappa_ESS_i[:,np.newaxis],ESS_r_list_i[:,np.newaxis]),axis = 1)\n",
    "    np.savetxt(output_file_i,data,header = header,comments = \"\")                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the properties from the saved text files\n",
    "ESS_dict = {}\n",
    "kappas_dict = {}\n",
    "\n",
    "for key in INN_dict.keys():\n",
    "\n",
    "    data_u = np.loadtxt(f\"./summary_ESS_lambda_{lambda_physics[0]}_{key}.txt\",skiprows = 1)\n",
    "\n",
    "    ESS_r_i = torch.Tensor(data_u[:,1])\n",
    "    kappas_i = torch.Tensor(data_u[:,0])\n",
    "\n",
    "    ESS_dict[key] = ESS_r_i\n",
    "    kappas_dict[key] = kappas_i\n",
    "\n",
    "fig_ESS,ax = plt.subplots(1,1,figsize = (12.5,4))\n",
    "\n",
    "for key in INN_dict.keys():\n",
    "\n",
    "    ax.plot(kappas_dict[key],ESS_dict[key],label = tags[key],color = colors_dict[key],lw = lw)\n",
    "\n",
    "    #Plot a marker at the position where the training data was located\n",
    "    for base_param in config_dict[key][\"config_data\"][\"init_data_set_params\"][\"kappa_list\"]:\n",
    "\n",
    "        #Interpolate betewwn the two closest points on the grid\n",
    "        idx = np.argmin(np.abs(kappas_dict[key] - base_param))\n",
    "        ax.plot(kappas_dict[key][idx],ESS_dict[key][idx],ls = \"\",marker = \"o\",markersize = 10, color = colors_dict[key])\n",
    "\n",
    "ax.set_xlabel(r\"$\\kappa$\",fontsize = fs)\n",
    "ax.set_ylabel(\"rel. ESS\",fontsize = fs)\n",
    "ax.tick_params(axis='both', which='major', labelsize=fs)\n",
    "plt.tight_layout()\n",
    "\n",
    "handles, labels = [], []\n",
    "\n",
    "for handle, label in zip(*ax.get_legend_handles_labels()):\n",
    "    handles.append(handle)\n",
    "    labels.append(label)\n",
    "\n",
    "# Add a single legend below all subplots\n",
    "fig_ESS.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.05), ncol=4,fontsize = fs)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ScalarTheory_ESS.pdf\",bbox_inches = \"tight\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the ESS for different random seeds\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kappas = 200\n",
    "\n",
    "experiment_folders = {\n",
    "    \"TRADE_grid\":\"../results/runs_ScalarTheory/Path to your trained model/lightning_logs/\",\n",
    "    \"NLL\":\"../results/runs_ScalarTheory/Path to your trained model/lightning_logs/\",\n",
    "    \"reverse_KL_NLL\":\"../results/runs_ScalarTheory/Path to your trained model/lightning_logs/\"\n",
    "}\n",
    "\n",
    "for key in experiment_folders.keys():\n",
    "\n",
    "    runs = os.listdir(experiment_folders[key])\n",
    "\n",
    "    storage_performance_indicators = np.zeros([len(runs),3])\n",
    "    storage_ESS = np.zeros([n_kappas,len(runs)+1])\n",
    "\n",
    "    output_file_i = f\"./summary_ESS_different_random_seeds_{key}.txt\"\n",
    "\n",
    "    if os.path.exists(output_file_i):\n",
    "        continue\n",
    "\n",
    "    for j,run in enumerate(runs):\n",
    "\n",
    "        folder_ij = experiment_folders[key] + run\n",
    "\n",
    "        INN_ij,config_ij = load_model_from_folder(folder_ij,device)\n",
    "\n",
    "        ESS_ij,kappas_ij = get_ESS(INN = INN_ij,config=config_ij,n_kappas = n_kappas)\n",
    "\n",
    "        storage_ESS[:,j+1] = ESS_ij\n",
    "\n",
    "    storage_ESS[:,0] = kappas_ij\n",
    "\n",
    "    #Save the results as text files\n",
    "    np.savetxt(output_file_i,storage_ESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_ESS_random_seed,ax_ESS_random_seed = plt.subplots(1,1,figsize = (25,10))\n",
    "\n",
    "for key in experiment_folders.keys():\n",
    "\n",
    "    data = np.loadtxt(f\"./summary_ESS_different_random_seeds_{key}.txt\")\n",
    "\n",
    "    kappas = data[:,0]\n",
    "\n",
    "    means = np.mean(data[:,1:],axis = 1)\n",
    "    stds = np.std(data[:,1:],axis = 1)\n",
    "\n",
    "    ax_ESS_random_seed.plot(kappas,means,label = tags[key],color = colors_dict[key],lw = lw)\n",
    "    ax_ESS_random_seed.fill_between(kappas,means - stds,means + stds,color = colors_dict[key],alpha = 0.3)\n",
    "\n",
    "handles, labels = [], []\n",
    "\n",
    "for handle, label in zip(*ax_ESS_random_seed.get_legend_handles_labels()):\n",
    "    handles.append(handle)\n",
    "    labels.append(label)\n",
    "\n",
    "ax_ESS_random_seed.tick_params(axis='both', which='major', labelsize=fs)\n",
    "fig_ESS_random_seed.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.025), ncol=4,fontsize = fs)\n",
    "\n",
    "ax_ESS_random_seed.set_xlabel(r\"$\\kappa$\",fontsize = fs)\n",
    "ax_ESS_random_seed.set_ylabel(\"rel. ESS\",fontsize = fs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ScalarTheory_ESS_random_seeds.pdf\",bbox_inches = \"tight\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
